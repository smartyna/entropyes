{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os #os.chdir(\"dir with *.m files\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeextractors as se\n",
    "import kachery as ka\n",
    "ka.set_config(fr='default_readonly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire spikeforest analysis results\n",
    "# Note: this needs to be updated -- will do that later\n",
    "SF = ka.load_object('sha1://1667383039f1170256e4e3445d46eff367e202e5/output.json', fr='default_readonly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of looping through all of the sorting results:\n",
    "sorting_results = SF['SortingResults']\n",
    "for sr in sorting_results[:10]:\n",
    "    print(f\"{sr['studyName']} {sr['recordingName']} {sr['sorterName']} {sr['firings']}\")\n",
    "    firings_path = ka.load_file(sr['firings'])\n",
    "    sorting = se.MdaSortingExtractor(firings_path)\n",
    "    print(len(sorting.get_unit_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pillow's CDM\n",
    "\n",
    "import matlab.engine\n",
    "from pyentropy import DiscreteSystem\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropies(sorting, method, word_length, sampling_frequency):\n",
    "    output = np.zeros((len(sorting.get_unit_ids())))\n",
    "    \n",
    "    sampF = sampling_frequency\n",
    "    wLen = word_length\n",
    "    unit_ids = sorting.get_unit_ids()\n",
    "    spike_trains = [sorting.get_unit_spike_train(unit_id=uid) for uid in unit_ids]\n",
    "    maxT = np.max([np.max(st) for st in spike_trains]) / sampling_frequency\n",
    "    for ii, unit_id in enumerate(unit_ids):\n",
    "        spk = sorting.get_unit_spike_train(unit_id=unit_id)\n",
    "        binSize = 0.05 * sampF \n",
    "        bins = np.arange(0, maxT*sampF, binSize)\n",
    "        spkCount,_ = np.histogram(spk, bins)\n",
    "        spkCount[spkCount>1] = 1\n",
    "            \n",
    "        i = 0\n",
    "        words = None\n",
    "        while i<len(spkCount)-wLen:\n",
    "            if words is None:\n",
    "                words = spkCount[i:i+wLen]\n",
    "                i += wLen #increase counter by wLen\n",
    "            else:\n", 
    "                words = np.vstack((words,spkCount[i:i+wLen]))\n",
    "                i += wLen\n",
    "        response = np.zeros(words.shape[0]).astype(int)\n",
    "        xm = np.max(spkCount)+1\n",
    "        # todo: this line only applies to a subset of the methods\n",
    "        sys = DiscreteSystem(words.T.astype(int), (wLen,xm), response, (1,1))\n",
    "        if method == 'plugin':\n",
    "            sys.calculate_entropies(method='plugin', calc=['HX'])\n",
    "            output[ii] = sys.H_plugin['HX']\n",
    "        elif method == 'pt':\n",
    "            sys.calculate_entropies(method='pt', calc=['HX'])\n",
    "            output[ii] = sys.H_pt['HX']\n",
    "        elif method == 'qe':\n",
    "            sys.calculate_entropies(method='qe', calc=['HX'])\n",
    "            output[ii] = sys.H_qe['HX']\n",
    "        elif method == 'CDM':\n",
    "            output[ii] = eng.entropyCDM(matlab.double(words.tolist()), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firings_path = ka.load_file(sorting_results[0]['firings'])\n",
    "sorting = se.MdaSortingExtractor(firings_path)\n",
    "calculate_entropies(sorting, method='pt', word_length=5, sampling_frequency=30000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
